[[rg-landscape-standard-section]]
== OGC GeoPose in Context

In this section of the reviewer’s guide, we list the Standards Development Organizations (SDOs) and standards that specify data objects that convey the same information as one or more of the eight forms of GeoPose.
As a convention for the remainder of this section, we use the term "GeoPose" as a shorthand for any of the specified forms of the OGC GeoPose standard.

The key question this section will answer is where and how GeoPose fits into the landscape of standards. By examining some of the relevant standards, this section illustrates the gaps which GeoPose fills.

There are many existing and emerging standards for position and orientation information. They have emerged from requirements defined in different industries: aviation, planetary sciences, maritime, robotics, autonomous driving, satellite positioning and aerospace, to name a few. There is good practice in commercial and other domains for expressing the position and orientation of entities in all these fields. These existing standards cover different scales, for different purposes, different information environment: sometimes graphical, sometimes geospatial.

=== OGC GeoPose Connects Objects to their Representation
There are conceptual and actual data pipelines that connect the real world and the objects in it with the representations in information and graphics systems. A number of the critical standards define how those pipelines are developed and interoperate or fit together.

In a standard Web browser, information is displayed on a plane. There is a need for a standard to represent information retrieved from the Web on the 2D display plane in a manner that is sufficiently fast to provide XR experiences. W3C WebXR focuses on this need.

In order to establish this data flow, there is a need in real graphics systems to locate those objects within a 3D local stage (or scene) so that when the user’s head or perceived objects move within that “stage”, the graphics systems can address those movements and changes correctly. Khronos OpenXR focuses on that stage of the pipeline.

On the other side, the OGC has been working on how sensor systems measure these changes in position and orientation. How does a system model the sensor that’s capturing all the data about the features (e.g. objects) in its environment, including where they are and how the system represents them in a local 2D or 3D environment? OGC Sensor Web Enablement, particularly Observations & Measurements and SensorML, addresses these needs.

Each of these stages in the pipeline need to exchange data between themselves. How do you get the position and orientation of anything from anywhere to anywhere, into and out of these interactive environments? That’s where GeoPose comes in. GeoPose defines the data structure(s) to pass position and orientation information between elements in the pipeline.

=== OGC GeoPose in the Landscape of Standards
The primary source of inspiration for GeoPose was the NASA SPICE framework because it is able to cover any scale from interplanetary and interstellar to specific local objects. NASA designed SPICE to address significant challenges in looking at both ephemeris objects (fixed, or on predictable paths) and objects that have changeable positions and orientations such as satellites, cameras, and other sensors. Representing different frames for these objects and being able to transform between them is really useful. SPICE is a formalism that is much larger than one needs for a simple or basic implementation, but an incredibly appropriate foundation from which the SWG was inspired.

OGC Moving Features was also taken into account when GeoPose was designed. Although it describes object position and orientation, Moving Features (MF) is focused on a particular set of use cases with an emphasis on sensor streams, digital exhausts, and location information (usually GPS) coming off of vehicles in a municipal environment. It accomplishes this compactly so that the data can be easily incorporated into analytical and visual applications.

OGC Moving Features and GeoPose have distinct roles and are complementary. Moving Features is focused on a local, municipal scale, and rapid streams of measurements. Getting observations in and out of municipal management and other platforms easily and efficiently is one of the roles that GeoPose plays.

The OGC Sensor Web Enablement suite of standards deals with how to work with sensors and getting useful observations out of them.

image::./images/landscape-standard-ef0fe.png

On the right of this figure is a schematic showing the workflows that are enabled in Observations and Measurements, in Semantic Sensor Networks, and with encodings such as SWE Common that enable transport of sensor outputs (observations). Another important part of these standards, SensorML, models the sensor process itself, from an initial environmental stimulus to how a measurement is recorded as an observation and recognized as an observed property of a real world object.

If this is a directed sensor (e.g. camera), orientation is an essential aspect of the sensor model. The result potentially includes the positions and orientations of both the sensor / platform and any observed entities in the world, although the sensor position and orientation may be secondary to the primary objective of observing the positions and orientations of these observed entities, e.g. cars. GeoPose permits systems to get the position and orientation in and out of SWE-compliant platforms or devices without losing any resolution or introducing delays.

Pose is essential for combining physical and digital entities in visual scenes for them to be used by a service or a user, particularly if entities are being brought into a scene from very different source contexts, and regardless of where they are in space.

Khronos OpenXR handles poses, particularly within specific spaces (frames of reference). It defines a set of reference spaces (view, local and stage); and specifies the model in which graphics hardware can use the pose in rendering objects. Within a particular graphical system, it is effective but GeoPose adds the capability to bring in a pose from any source in any frame of reference.

GeoPose can also relate the frame of reference of a Web browser window to a virtual world or the real world.

Geocentric (earth-based) position and orientation are the basis for all these integrations. OGC GeoPose provides that usable common ground, both the geospatial expertise that OGC has cultivated for many years and digital representation of physical space as the most common denominator among all these systems and representations.

To summarize, there are a number of well-developed standards for position and orientation. What these lack is a means for position and orientation information to be passed between them in a manner that is independent of graphical system, applications scene, frame of reference, and technology. OGC GeoPose offers portability of information between all these domains and systems.

The approaches to this issue that have been published in other standards prior to introduction of GeoPose appear in the tables below.

=== Standards which Could Reference GeoPose in Normative Clauses

==== OGC Standards

The OGC has many positioning and location standards, some also express orientation. They do so in different scales and with different global and/or local coordinate reference systems. Some also deal with different time scales. However, these standards are not designed for sharing position and orientation.

Some standards (such as OGC CDB) deal with fixed infrastructure, or with somewhat more specialized information, such as KML and IndoorGML. Some deal with expressing location and orientation in very dynamic and real time scales, such as Sensor Web Enablement and Moving Features.

Our assessment of the pose-related elements of other OGC standards are summarised in the table below under the following headings:

 - *Graphic/Virtual Context*: does the standard relate only to a computer graphics context, abstracted from the outside world, or does the standard deal with virtual models of the real world?
 - *Local SRS*: does the standard allow a local spatial reference system (SRS), independent of a wider geographical framework, to be used to define coordinates?
 - *Geodetic SRS*: does the standard allow a spatial reference system connected to the shape of the Earth or its gravity field as the basis for coordinates?
 - *6DOF as entity or attributes*: if the standard stores position and orientation for objects, is this information stored as attributes of the objects or does it use a pose entity in the data model with an association between the pose entity and the object entity?
 - *Temporality*: does the standard manage temporal information for the objects represented?

|===
|Standard|Graphic/Virtual Context|Local SRS|Geodetic SRS|6DOF as entity or attributes?|Temporality|Remark

|Moving Features|Virtual|Y|Y|Attributes of temporal geometry|Y|

|Sensor Web Enablement (SWE)|Virtual|Y|Y|Attributes|Y|

|GML|Virtual|Y|Y|Attributes. Direction only (no roll)|Y|v3.2.1

|CityGML|Both|Y|Y|Attributes|Y|

|IndoorGML|Virtual|Y|Y|No orientation|IndoorPOI extension|Based on GML

|"CDB (Common Database)"|Both|Y|Y|Y|Y|

|KML|Both|Y|Y|Entity|Y|

|Observations, Measurements and Samples (OMS)|Both|Y|Y|Both|Y|

|SensorThings API|Virtual|Y|Y|Attributes|Y|

|IMDF|Both|Y|Y|Attributes|Y|

|3D Tiles|Both|Y|Y|Entity|Y|Based on glTF

|JSONFG| ? |?|?|?|?|under development, ask Josh L

|===

Note: 3D Tiles is basically a binary, encapsulated glTF with georeferencing.

Note: In OMS, where location is foreseen, it is always an ISO19107 Geometry Type. Temporal information is provided both in the Observation and the Deployment, utilizing TM_Object or TM_Period. Temporal attributes are defined in ISO19108.

==== Other SDOs

There are other standards development organizations (SDO’s) that deal with location and orientation for graphics. They are compiled in the tables below. Work done in the W3C defines how systems express location and orientation for browsers. The Motion Imagery Standards Board (MISB) has standards for moving cameras. ISO also has sections of its standards in SC 24, such as the X3D standards, that encode orientation and position in graphics. In the Khronos Group, there are standards such as OpenXR and glTF that specify how to form digital assets that encode position and orientation

__Khronos Group__
|===
|*Standard* |*Graphic/Virtual Context* |*Geographically-referenced Local SRS* |*Geodedic CRS* |*6DOF as entity or attribute?* |*Temporality*

|glTF
|Both
|Y
|N
|Entity
|Y

|OpenXR
|Virtual
|Y
|N
|Entity
|Y

|===

link:https://www.khronos.org/registry/OpenXR/specs/1.0/html/xrspec.html#XR_MSFT_spatial_anchor[This OpenXR Extension for Microsoft Spatial Anchors] allows an application to create a spatial anchor, an arbitrary freespace point in the user’s physical environment that will then be tracked by the runtime. The runtime should then adjust the position and orientation of that anchor’s origin over time as needed, independently of all other spaces and anchors, to ensure that it maintains its original mapping to the real world.

__W3C__
|===
|*Standard* |*Graphic/Virtual Context* |*Geographically-referenced Local SRS* |*Geodedic CRS* |*6DOF as entity or attribute?* |*Temporality* |*Remark*

|https://w3c.github.io/geolocation-api/[Geolocation API]
|Virtual
|No
|Position & heading only
|Attributes
|Yes
|Working Draft (Nov 21)

|https://www.w3.org/TR/orientation-sensor/[Orientation Sensor]
|Virtual
|Orientation only
|Orientation only
|Attributes
|Yes
|Editor's Draft (Nov 21)

|https://www.w3.org/TR/webxr/[WebXR Device API]
|Virtual
|Yes
|No
|Entity
|Yes
|Working Draft (Nov 21)
|===

Levels of support for HTML features in current web browsers can be gauged from https://wpt.fyi/results[W3C Web Platform Test results].

From the Immersive Web WebXR Device API documentation: link:https://immersive-web.github.io/webxr/#xrspace-interface[XRSpace] and link:https://immersive-web.github.io/webxr/#pose[XR Pose]
An XRSpace represents a virtual coordinate system with an origin that corresponds to a physical location. Spatial data that is requested from the API or given to the API is always expressed in relation to a specific XRSpace at the time of a specific XRFrame. Numeric values such as pose positions are coordinates in that space relative to its origin. The interface is intentionally opaque.

__Motion Imagery Standards Board (MISB)__
|===
|*Standard* |*Graphic/Virtual Context* |*Geographically-referenced Local SRS* |*Geodedic CRS* |*6DOF as entity or attribute?* |*Temporality*
|https://www.gwg.nga.mil/misb/docs/standards/ST0601.17.pdf[MISB ST 0601]
|Virtual
|Sensor position & orientation relative to platform
|Platform position & orientation
|Attributes
|UTC & media time

|https://www.gwg.nga.mil/misb/docs/standards/ST0801.8.pdf[MISB ST 0801]
|Virtual
|No
|Camera position & orientation
|Attributes
|UTC & media time
|===

__Third Generation Partnership Project (3GPP)__
|===
|*Standard* |*Graphic/Virtual Context* |*Geographically-referenced Local SRS* |*Geodedic CRS* |*6DOF as entity or attribute?* |*Temporality*
|https://portal.3gpp.org/desktopmodules/Specifications/SpecificationDetails.aspx?specificationId=1441[3GP (26.244)]
|Virtual
|No
|Y
|Attributes
|Media time
|===

__Camera & Imaging Products Association (CIPA/JEITA)__
|===
|*Standard* |*Graphic/Virtual Context* |*Geographically-referenced Local SRS* |*Geodedic CRS* |*6DOF as entity or attribute?* |*Temporality*
|https://www.cipa.jp/std/documents/e/DC-X008-Translation-2019-E.pdf[Exif]
|Virtual
|No
|Position & heading only
|Attributes
|UTC
|===


__International Organization for Standardization (ISO)__
|===
|*Standard* |*Graphic/Virtual Context* |*Geographically-referenced Local SRS* |*Geodedic CRS* |*6DOF as entity or attribute?* |*Temporality*
|https://www.iso.org/standard/54166.html[Spatial Reference Model (18026)]
|Virtual
|No
|Position only
|Attributes
|UTC

|https://mpeg.chiariglione.org/standards/mpeg-i[MPEG Immersive Video (MIV) MPEG-I (23090)]
|Virtual
|No
|Yes
|Attributes
|Media time


|ISO19107
|?
|?
|?
|?
|?

|ISO19108
|?
|?
|?
|?
|Y

|===


__Institute of Electrical and Electronics Engineers (IEEE)__
|===
|*Standard* |*Graphic/Virtual Context* |*Geographically-referenced Local SRS* |*Geodedic CRS* |*6DOF as entity or attribute?* |*Temporality* |*Remark*
|Distributed Interactive Simulation (1278)
|Virtual
|No
|Position only
|Attribute
|Y
|

|Smart Transducer Interface (1451)
|N
|Y
|Y
|Entity
|Y
|Based on GML
|===

__BuildingSmart__
|===
|*Standard* |*Graphic/Virtual Context* |*Geographically-referenced Local SRS* |*Geodedic CRS* |*6DOF as entity or attribute?* |*Temporality*
|IFC
|Y
|Y
|Y
|No
|No
|===

IfcSite and other IfCProducts permits topologic orientation, but not 6DOF. IFCSite lets users provide the WGS84 location (lat,lng,alt) of  "the single geographic reference point for (http://standards.buildingsmart.org/MVD/RELEASE/IFC4/ADD2_TC1/RV1_2/HTML/schema/ifcproductextension/lexical/ifcsite.htm)[this site)]"

For orientation they refer to the concept of "true north": "The world coordinate system, established at the IfcProject.RepresentationContexts, may include a definition of the true north within the XY plane of the world coordinate system, if provided, it can be obtained at IfcGeometricRepresentationContext.TrueNorth."


__ASTM__
|===
|*Standard* |*Graphic/Virtual Context* |*Geographically-referenced Local SRS* |*Geodedic CRS* |*6DOF as entity or attribute?* |*Temporality*
|E57 3D Imaging Data Exchange (E2807-11 (2019))
|No
|Y
|Y
|Attribute
|Y
|===

The core capabilities of the E57 data exchange format link:http://libe57.org/features.html[includes fifteen features.]

==== Space Science
There are also specifications (standards) that are developed for and used by industries/domains.

The Observation Geometry System NASA uses for space science missions is called SPICE.

[INSERT MIKEL's FIGURE HERE]

The OGC GeoPose SWG has chosen to make reference particularly to SPICE in this document as an elegant system which ties together ephemeris information (including position and orientation data) in contexts ranging from the Earth system through to spacecraft, solar system (with the link:https://en.wikipedia.org/wiki/Earth-centered_inertial['J2000']  fundamental inertial reference system) and planetary bodies. The SWG members were inspired by some of the concepts, particularly the ideas of frame of reference transformations and of satellites, constellations of satellites and other objects in orbit around the Earth. SPICE handles complex situations such as the relative pointing of spacecraft in motion around other bodies in the Solar System - this flexibility points to a complete and elegant solution.

While the SWG appreciated the full treatment of frame transformation in the SPICE system, the members took the approach of reducing the scope to Earth-based systems in version 1 of the GeoPose standard. The intention has been to permit later extension to a wider solar system viewpoint.

A tutorial presentation about SPICE is available link:https://naif.jpl.nasa.gov/pub/naif/toolkit_docs/Tutorials/pdf/individual_docs/03_spice_overview.pdf[here].

The link:https://naif.jpl.nasa.gov/pub/naif/toolkit_docs/Tutorials/pdf/individual_docs/21_fk.pdf[Frames Kernel] is the key component of SPICE to link reference frames and which in particular inspired the frame transformations in OGC GeoPose.


__Space Data Standards__

International space data standards are documented in https://ccsds.org[Consultative Committee for Space Data Systems (CCSDS)] Blue Books. Spacecraft position and orientation are described as _attitude_ as described in section 5.3 of https://public.ccsds.org/Pubs/500x0g4.pdf[CCSDS Navigation Data - Definitions and Conventions]. Typical GeoPose use cases include antenna tracking, sun sensor, star sensor, gyro package and horizon sensor.

This URL is a convenient place to view many space data standards
URL: http://spacedatastandards.org/
